{
  "model_size": "tiny",
  "train_data": "D:\\TRM\\data\\xlam_1k_swift.json",
  "eval_data": "D:\\TRM\\data\\xlam_val_200_swift.json",
  "tokenizer_path": "checkpoints/small/tokenizer.model",
  "vocab_size": 8000,
  "model_type": "bpe",
  "batch_size": 4,
  "num_epochs": 2,
  "learning_rate": 0.0001,
  "weight_decay": 0.01,
  "warmup_ratio": 0.1,
  "min_lr_ratio": 0.1,
  "save_dir": "checkpoints",
  "eval_every": 1,
  "device": "cuda",
  "use_ema": true,
  "ema_decay": 0.999,
  "hidden_dim": 128,
  "num_layers": 2,
  "num_heads": 4,
  "reasoning_dim": 64,
  "action_dim": 32,
  "num_recursions": 2,
  "max_supervision_steps": 2,
  "deep_recursion_steps": 1,
  "use_original_trm_grad": false,
  "q_threshold": 0.8,
  "dropout": 0.1,
  "use_swiglu": false,
  "use_rmsnorm": false
}